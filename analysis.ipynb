{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analyzing Wikipedia Clickstream Data***\n",
    "Introduction to Clickstream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+----------+\n",
      "|         source_page|         target_page|link_category|link_count|\n",
      "+--------------------+--------------------+-------------+----------+\n",
      "|        other-search|Hanging_Gardens_o...|     external|     47000|\n",
      "|         other-empty|Hanging_Gardens_o...|     external|     34600|\n",
      "|Wonders_of_the_World|Hanging_Gardens_o...|         link|     14000|\n",
      "|             Babylon|Hanging_Gardens_o...|         link|      2500|\n",
      "+--------------------+--------------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "#create a sample dataset to test whether the apsrk work\n",
    "# sample_clickstream_counts = [\n",
    "#     [\"other-search\", \"Hanging_Gardens_of Babalon\", \"external\", 47000],\n",
    "#     [\"other-empty\", \"Hanging_Gardens_of_Babylon\", \"external\", 34600],\n",
    "#     [\"Wonders_of_the_World\", \"Hanging_Gardens_of_Babylon\", \"link\", 14000],\n",
    "#     [\"Babylon\", \"Hanging_Gardens_of_Babylon\", \"link\", 2500]\n",
    "# ]\n",
    "# clickstream_counts_rdd = spark.sparkContext.parallelize(sample_clickstream_counts)\n",
    "# clickstream_sample_df = clickstream_counts_rdd.toDF([\"source_page\", \"target_page\", \"link_category\", \"link_count\"])\n",
    "# clickstream_sample_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:===============================================>        (11 + 2) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------+-------------+----------+\n",
      "|source_page          |target_page           |link_category|link_count|\n",
      "+---------------------+----------------------+-------------+----------+\n",
      "|other-empty          |Main_Page             |external     |119417306 |\n",
      "|Charles_Tilly        |Joseph_L._Buttenwieser|link         |12        |\n",
      "|other-search         |Lyle_and_Erik_Menendez|external     |11111073  |\n",
      "|Charles_Tilly        |Talcott_Parsons       |link         |12        |\n",
      "|other-empty          |Hyphen-minus          |external     |10101208  |\n",
      "|Charles_Tiu          |Mighty_Sports         |link         |12        |\n",
      "|other-internal       |Main_Page             |external     |7254647   |\n",
      "|Charles_Tolliver     |Action_Action_Action  |link         |12        |\n",
      "|other-empty          |Cleopatra             |external     |4087571   |\n",
      "|Charles_Town,_Jamaica|Jamaican_Maroons      |link         |12        |\n",
      "+---------------------+----------------------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# download the dataset and unzip \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Wikipedia Clickstream\").getOrCreate()\n",
    "clickstream = spark.read.csv(\n",
    "    \"clickstream-enwiki-2024-09.tsv\", \n",
    "    sep=\"\\t\", \n",
    "    header=False, \n",
    "    inferSchema=True\n",
    ").toDF(\"source_page\", \"target_page\", \"link_category\", \"link_count\")# add the column name, no need to transfer to df when iport from csv/tsv\n",
    "clickstream.show(10, truncate=False)\n",
    "\n",
    "# download the dataset without unzip \n",
    "# clickstream = spark.read.csv(\n",
    "#     \"clickstream-enwiki-2024-09.tsv.gz\", \n",
    "#     sep=\"\\t\", \n",
    "#     header=False, \n",
    "#     inferSchema=True\n",
    "# ).toDF(\"source_page\", \"target_page\", \"link_category\", \"link_count\")\n",
    "\n",
    "# clickstream.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying Clickstream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:===============================================>        (11 + 2) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+--------------------------+-------------+-----------+\n",
      "|source_page                       |target_page               |link_category|click_count|\n",
      "+----------------------------------+--------------------------+-------------+-----------+\n",
      "|other-search                      |Hanging_Gardens_of_Babylon|external     |42642      |\n",
      "|Seven_Wonders_of_the_Ancient_World|Hanging_Gardens_of_Babylon|link         |19759      |\n",
      "|other-empty                       |Hanging_Gardens_of_Babylon|external     |9154       |\n",
      "|Wonders_of_the_World              |Hanging_Gardens_of_Babylon|link         |8593       |\n",
      "|Babylon                           |Hanging_Gardens_of_Babylon|link         |3064       |\n",
      "|Nebuchadnezzar_II                 |Hanging_Gardens_of_Babylon|link         |2414       |\n",
      "|other-internal                    |Hanging_Gardens_of_Babylon|external     |1593       |\n",
      "|other-external                    |Hanging_Gardens_of_Babylon|external     |434        |\n",
      "|Tower_of_Babel                    |Hanging_Gardens_of_Babylon|link         |393        |\n",
      "|Pistachio                         |Hanging_Gardens_of_Babylon|link         |209        |\n",
      "+----------------------------------+--------------------------+-------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a temporary view in the metadata for this `SparkSession` to make the data. createOrReplaceTempView() for tempory view,createGlobalTempView() for global view\n",
    "clickstream.createOrReplaceTempView(\"clickstream\")\n",
    "\n",
    "# Filter and sort the DataFrame using PySpark DataFrame methods\n",
    "clickstream\\\n",
    "    .filter(clickstream.target_page == 'Hanging_Gardens_of_Babylon')\\\n",
    "    .orderBy('click_count', ascending=False)\\\n",
    "    .show(10, truncate=False)\n",
    "\n",
    "# queryable with `sparkSession.sql()`\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM clickstream\n",
    "    WHERE target_page = 'Hanging_Gardens_of_Babylon'\n",
    "    ORDER BY click_count DESC\n",
    "    \"\"\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n",
      "[Stage 51:==========================>                              (6 + 7) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=38972Kb max_used=39889Kb free=92099Kb\n",
      " bounds [0x00000001079e8000, 0x000000010a128000, 0x000000010f9e8000]\n",
      " total_blobs=14299 nmethods=13343 adapters=865\n",
      " compilation: disabled (not enough contiguous free space left)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:===============================================>        (11 + 2) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|link_category|sum(click_count)|\n",
      "+-------------+----------------+\n",
      "|link         |2216084832      |\n",
      "|other        |48024351        |\n",
      "|external     |4261629291      |\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Aggregate the DataFrame using PySpark DataFrame Methods \n",
    "clickstream\\\n",
    "    .groupBy('link_category')\\\n",
    "    .sum()\\\n",
    "    .show(truncate=False)\n",
    "\n",
    "# Aggregate the DataFrame using SQL\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT link_category, SUM(click_count) FROM clickstream\n",
    "    GROUP BY link_category\n",
    "    \"\"\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the `internal_clickstream` DataFrame to a series of CSV files in `./results/article_links_csv/`\n",
    "internal_clickstream = clickstream\\\n",
    "    .select([\"source_page\", \"target_page\", \"click_count\"])\\\n",
    "    .filter(clickstream.link_category == 'link')\n",
    "\n",
    "internal_clickstream\\\n",
    "    .write\\\n",
    "    .csv('./results/article_links_csv/', mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
